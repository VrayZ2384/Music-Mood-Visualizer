![image](https://github.com/VrayZ2384/Music-Mood-Visualizer/assets/66193128/e28d788e-4c28-44e1-96a5-d4ca20862e46)# Music-Mood-Visualizer

## Overview

The Music Mood Visualizer is a multi-modal Generative Adversarial Network (GAN) project that utilizes generative AI and Python, along with the PyTorch framework. This innovative system analyzes audio data from music and generates customized images and videos that match the mood of the song.

## Features

- Analyzes audio data from a given YouTube link.
- Automatically determines the mood of the song (Happy, Sad, or Neutral).
- Generates images and videos that reflect the song's mood.
- Customizable prompts allow users to influence the generated visuals.
- Enhances creative content for musicians, content creators, and social media influencers.
- Demonstrates the potential of AI in creative applications.

## How it Works

1. **Input**: Users provide a YouTube link to a song they want to analyze and also provide prompts to customize the visuals.
![image](https://github.com/VrayZ2384/Music-Mood-Visualizer/assets/66193128/caf5d1e7-d4a1-40b8-bc6e-6c259384d37a)

2. **Mood Analysis**: The system extracts audio features from the song to determine its mood (Happy, Sad, or Neutral).
![image](https://github.com/VrayZ2384/Music-Mood-Visualizer/assets/66193128/0c301a90-6aeb-4570-a341-885fab6f8715)

3. **Output**: Based on the mood, the system generates images and videos that match the song's emotional tone and the users receive stunning visuals that complement their music, ready to be used in various creative projects.
![image](https://github.com/VrayZ2384/Music-Mood-Visualizer/assets/66193128/8dcc8368-e53e-414b-b89e-1170c827dbf5)
![image](https://github.com/VrayZ2384/Music-Mood-Visualizer/assets/66193128/536f51a3-6663-4503-85ed-36679151c426)
![image](https://github.com/VrayZ2384/Music-Mood-Visualizer/assets/66193128/5ea969a0-9838-4eb1-ac92-a7b282ffd981)

https://github.com/VrayZ2384/Music-Mood-Visualizer/assets/66193128/b241ebe7-94d3-4327-86ab-cd9282560c8c

## Technical Skills and Tools Used

- Generative Adversarial Networks (GANs)
- PyTorch
- Python
- PyTube (for YouTube data retrieval)
- Librosa (for audio analysis)
- Multi-modal AI using CLIP
- Image and Video Generation
- User Interface (UI) with Jupyter Widgets

## Usage

1. Provide a YouTube link to a song you want to analyze.

2. Wait for the system to determine the song's mood.

3. Optionally, enter prompts to customize the generated visuals.

4. Click the "Generate" button to create visuals that match the song's mood.

5. Download and use the generated images and videos for your creative projects.

## Recommended Environment

It is recommended to use Google Colab for running this project, as Google's GPUs make computation more efficient and accelerates the visual generation process.

## License

This project is licensed under the GNU General Public License v3.0 - see the LICENSE file for details.

## Acknowledgments

- [PyTorch](https://pytorch.org/)
- [PyTube](https://pytube.io/)
- [Librosa](https://librosa.org/)
- [CLIP](https://openai.com/research/clip)

